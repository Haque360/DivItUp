{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haque360/DivItUp/blob/main/jupyters/colab_example_images_mixing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAce3PlMC69_",
        "outputId": "07a81e69-c160-40a9-9b70-2d492ab7a090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'images_mixing' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/TheDenk/images_mixing.git\n",
        "!pip install -r ./images_mixing/requirements.txt > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "HUsR40FnDq5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.16.1 transformers==4.38.0 open-clip-torch==2.20.0\n"
      ],
      "metadata": {
        "id": "9ewcJJWEpBUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  huggingface_hub==0.25.0"
      ],
      "metadata": {
        "id": "Exgz1efDpedf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"jax[cuda12_pip]==0.4.23\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "id": "7Cs0DAuOpioP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import sys\n",
        "sys.path.append('./images_mixing')\n",
        "\n",
        "import torch\n",
        "import open_clip\n",
        "from PIL import Image\n",
        "from open_clip import SimpleTokenizer\n",
        "from diffusers import DiffusionPipeline\n",
        "from transformers import CLIPFeatureExtractor, CLIPModel\n",
        "\n",
        "from utils import show_images"
      ],
      "metadata": {
        "id": "qM7wwPImC8rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load additional models: CLIP and CoCa"
      ],
      "metadata": {
        "id": "kGkg-GTwDjFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = CLIPFeatureExtractor.from_pretrained(\n",
        "    \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"\n",
        ")\n",
        "clip_model = CLIPModel.from_pretrained(\n",
        "    \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\", torch_dtype=torch.float16\n",
        ")\n",
        "coca_model = open_clip.create_model('coca_ViT-L-14', pretrained='laion2B-s13B-b90k').to('cuda')\n",
        "coca_model.dtype = torch.float16\n",
        "coca_transform = open_clip.image_transform(\n",
        "    coca_model.visual.image_size,\n",
        "    is_train = False,\n",
        "    mean = getattr(coca_model.visual, 'image_mean', None),\n",
        "    std = getattr(coca_model.visual, 'image_std', None),\n",
        ")\n",
        "coca_tokenizer = SimpleTokenizer()"
      ],
      "metadata": {
        "id": "M0y0LwfKC8uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DiffusionPipeline from local .py file"
      ],
      "metadata": {
        "id": "Lqoed9MRDy8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mixing_pipeline = DiffusionPipeline.from_pretrained(\n",
        "    # \"stabilityai/stable-diffusion-2-base\",\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    custom_pipeline=\"./images_mixing/images_mixing.py\",\n",
        "    clip_model=clip_model,\n",
        "    feature_extractor=feature_extractor,\n",
        "    coca_model=coca_model,\n",
        "    coca_tokenizer=coca_tokenizer,\n",
        "    coca_transform=coca_transform,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "mixing_pipeline = mixing_pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "cefIpOocC8xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate"
      ],
      "metadata": {
        "id": "5w3pqAmXD2xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch transformers==4.30.2"
      ],
      "metadata": {
        "id": "o0RKg0qErQ-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator(device=\"cuda\").manual_seed(17)\n",
        "\n",
        "content_image = Image.open('./images_mixing/images/cat.jpeg').convert(\"RGB\")\n",
        "style_image = Image.open('./images_mixing/images/bread.png').convert(\"RGB\")\n",
        "\n",
        "pipe_images = mixing_pipeline(\n",
        "    num_inference_steps=50,\n",
        "    content_image=content_image,\n",
        "    style_image=style_image,\n",
        "    content_prompt=None,  # If None will be automaticly created with CoCa\n",
        "    style_prompt=None,  # If None will be automaticly created with CoCa\n",
        "    noise_strength=0.4,  # Noise for start point (content image). More noise - more new information.\n",
        "    slerp_latent_style_strength=0.25,  # Amount Style image information for start point\n",
        "    slerp_prompt_style_strength=0.99,  # Amount Style prompt information for diffusion steps\n",
        "    slerp_clip_image_style_strength=0.9,  # Amount Style image information for diffusion steps\n",
        "    guidance_scale=9.0,\n",
        "    batch_size=1,\n",
        "    clip_guidance_scale=100,\n",
        "    generator=generator,\n",
        "    print_promts=True,\n",
        ").images\n",
        "\n",
        "show_images([content_image, style_image, pipe_images[0]], figsize=(16, 8))"
      ],
      "metadata": {
        "id": "7djajDv5D2Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNInlehkC82N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKvyXOrrHION"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}